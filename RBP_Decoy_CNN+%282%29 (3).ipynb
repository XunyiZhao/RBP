{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBP='1A34 1AQ3 1BMV 1F7V 1H4Q 1JBT 1L9A 1MZP 1WMQ 1YYK 1ZL3 2ANN 2ATW 2AZ2 2BX2 2DR2 2DU4 2G4B 2GXB 3AMT'\n",
    "#the rbp we gonna analyze\n",
    "rbp=RBP.split()\n",
    "len(rbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "for i in range(20):\n",
    "    f = open(rbp[i]+'/complex1.pdb')\n",
    "    for x in f.readlines():\n",
    "        if x.split()[3] not in name:\n",
    "            name.append(x.split()[3])\n",
    "    f.close()\n",
    "len(name)\n",
    "#save all the elements from the ebp\n",
    "#in fact, after 24 there is no useful elements, just to prevent bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "protein = name[0:20]\n",
    "protein.remove('ASER')\n",
    "protein.remove('AARG')\n",
    "protein.append('HIS')\n",
    "protein.append('CYS')\n",
    "protein.extend(['A','G','C','U' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num = 24\n",
    "comp_num = 100\n",
    "total = 20*comp_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:46<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "#measure the size of the RBP\n",
    "\n",
    "size=np.zeros([20,comp_num,6])\n",
    "for i in tqdm(range(20)):#for every rbp\n",
    "    for j in range(comp_num):\n",
    "        r=rbp[i]\n",
    "        f = open(r+'/complex%d.pdb'%(j+1))\n",
    "        tmp_x = []\n",
    "        tmp_y = []\n",
    "        tmp_z = []\n",
    "        for x in f.readlines():\n",
    "            tmp_z.append(np.float32(x[-9:-1]))\n",
    "            tmp_y.append(np.float32(x[-17:-9]))\n",
    "            tmp_x.append(np.float32(x[-25:-17]))\n",
    "        size[i,j,0]=max(tmp_x)\n",
    "        size[i,j,3]=min(tmp_x)\n",
    "        size[i,j,1]=max(tmp_y)\n",
    "        size[i,j,4]=min(tmp_y)\n",
    "        size[i,j,2]=max(tmp_z)\n",
    "        size[i,j,5]=min(tmp_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:15<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "length=np.zeros([20,comp_num,3])\n",
    "length[:,:,0]=(size[:,:,0]-size[:,:,3])/num\n",
    "length[:,:,1]=(size[:,:,1]-size[:,:,4])/num\n",
    "length[:,:,2]=(size[:,:,2]-size[:,:,5])/num\n",
    "coordinate=np.zeros((20,comp_num,num,num,num,24), dtype=np.int)\n",
    "for k in tqdm(range(20)):#for every rbp\n",
    "    for j in range(comp_num):\n",
    "        r=rbp[k]\n",
    "        f = open(r+'/complex%d.pdb'%(j+1))\n",
    "        t=f.readlines()[0].split()[-4]\n",
    "        cotmp=np.zeros(4)\n",
    "        f = open(r+'/complex%d.pdb'%(j+1))\n",
    "        for x in f.readlines():\n",
    "            #print(x)\n",
    "            if x[22:26]!=t and cotmp[3]!=0:\n",
    "                #print(cotmp,t,tmp)\n",
    "                position = cotmp[0:3]/cotmp[3]-size[k,j,3:]\n",
    "                #print(cotmp[0:3]/cotmp[3])\n",
    "                ix=position[0]//length[k,j,0]\n",
    "                iy=position[1]//length[k,j,1]\n",
    "                iz=position[2]//length[k,j,2]\n",
    "                #if ix > 10:\n",
    "                    #print(k,j,position)\n",
    "                if i < 24:\n",
    "                    coordinate[k,j,int(ix),int(iy),int(iz),i]+=1\n",
    "                cotmp=np.zeros(4)\n",
    "            #save center of the acid or RNA in coord\n",
    "\n",
    "            tmp=np.zeros(4)\n",
    "            tmp[2]+=np.float32(x[-9:-1])\n",
    "            tmp[1]+=np.float32(x[-17:-9])\n",
    "            tmp[0]+=np.float32(x[-25:-17])\n",
    "            tmp[3]+=1\n",
    "            #print(tmp)\n",
    "            cotmp+=tmp\n",
    "\n",
    "            #count every atom in each acid or RNA\n",
    "\n",
    "            n =x.split()[3]\n",
    "            i = name.index(n)     \n",
    "            t =x[22:26]\n",
    "            #update the tmp index \n",
    "\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = list(range(total))\n",
    "rd.shuffle(index)\n",
    "train_index = index[:-300]\n",
    "test_index = index[-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_coordinate = coordinate.reshape(20*comp_num,num,num,num,24)[train_index]\n",
    "test_coordinate = coordinate.reshape(20*comp_num,num,num,num,24)[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = np.zeros((20,comp_num))\n",
    "\n",
    "for k in range(20):\n",
    "    tmp=[]\n",
    "    f=open(rbp[k]+'/'+rbp[k]+'.rmsd.out.tensorflow')\n",
    "    for x in f.readlines()[1:]:\n",
    "        tmp.append(np.float32(x[23:32]))\n",
    "    target[k]=np.float32(tmp[0:comp_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_target = target.reshape(20*comp_num,1)[train_index]\n",
    "test_target = target.reshape(20*comp_num,1)[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,  num, num, num, 24], name='x_')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2x2(x):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def random_batch(data,label,size):\n",
    "    index =  np.random.choice(len(label), size, replace=False)\n",
    "    batch_data = data[index]\n",
    "    batch_label = label[index]\n",
    "    return batch_data,batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_image = tf.cast(tf.reshape(x, [-1, num, num, num, 24]),tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([3, 3, 3, 24, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv3d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([6, 6, 6, 32, 32])\n",
    "b_conv2 = bias_variable([32])\n",
    "h_conv2 = tf.nn.relu(conv3d(h_conv1, W_conv2) + b_conv2)\n",
    "\n",
    "h_pool1 = max_pool_2x2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv3 = weight_variable([4, 4, 4, 32, 32])\n",
    "b_conv3 = bias_variable([32])\n",
    "h_conv3 = tf.nn.relu(conv3d(h_pool1, W_conv3) + b_conv3)\n",
    "\n",
    "W_conv4 = weight_variable([5, 5, 5, 32, 32])\n",
    "b_conv4 = bias_variable([32])\n",
    "h_conv4 = tf.nn.relu(conv3d(h_conv3, W_conv4) + b_conv4)\n",
    "\n",
    "h_pool2 = max_pool_2x2x2(h_conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([int(num* num *num/2), 256])\n",
    "b_fc1 = bias_variable([256])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, int(num * num* num /2)])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob0')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([256, 1])\n",
    "b_fc2 = bias_variable([1])\n",
    "\n",
    "y_conv = tf.add(tf.matmul(h_fc1_drop, W_fc2) , b_fc2,name='y_conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, test loss 721.686\n",
      "step 30, test loss 401.073\n",
      "step 60, test loss 363.316\n",
      "step 90, test loss 238.588\n",
      "step 120, test loss 380.644\n",
      "step 150, test loss 271.923\n",
      "step 180, test loss 277.594\n",
      "step 210, test loss 331.216\n",
      "step 240, test loss 241.509\n",
      "step 270, test loss 283.441\n",
      "step 300, test loss 166.909\n",
      "step 330, test loss 233.589\n",
      "step 360, test loss 232.099\n",
      "step 390, test loss 167.911\n",
      "step 420, test loss 133.633\n",
      "step 450, test loss 163.951\n",
      "step 480, test loss 124.109\n",
      "step 510, test loss 244.315\n",
      "step 540, test loss 139.906\n",
      "step 570, test loss 142.561\n",
      "step 600, test loss 157.918\n",
      "step 630, test loss 193.053\n",
      "step 660, test loss 151.35\n",
      "step 690, test loss 165.745\n",
      "step 720, test loss 106.179\n",
      "step 750, test loss 166.402\n",
      "step 780, test loss 165.987\n",
      "step 810, test loss 116.528\n",
      "step 840, test loss 156.214\n",
      "step 870, test loss 190.227\n",
      "step 900, test loss 105.777\n",
      "step 930, test loss 174.264\n",
      "step 960, test loss 111.481\n",
      "step 990, test loss 144.018\n",
      "step 1020, test loss 153.285\n",
      "step 1050, test loss 140.144\n",
      "step 1080, test loss 135.57\n",
      "step 1110, test loss 109.409\n",
      "step 1140, test loss 100.31\n",
      "step 1170, test loss 128.665\n",
      "step 1200, test loss 167.329\n",
      "step 1230, test loss 96.7267\n",
      "step 1260, test loss 129.607\n",
      "step 1290, test loss 110.482\n",
      "step 1320, test loss 142.531\n",
      "step 1350, test loss 103.218\n",
      "step 1380, test loss 136.36\n",
      "step 1410, test loss 124.754\n",
      "step 1440, test loss 108.037\n",
      "step 1470, test loss 125.408\n",
      "step 1500, test loss 120.929\n",
      "step 1530, test loss 135.91\n",
      "step 1560, test loss 142.591\n",
      "step 1590, test loss 111.481\n",
      "step 1620, test loss 116.651\n",
      "step 1650, test loss 83.8665\n",
      "step 1680, test loss 76.9886\n",
      "step 1710, test loss 100.053\n",
      "step 1740, test loss 71.4154\n",
      "step 1770, test loss 136.884\n",
      "step 1800, test loss 89.1602\n",
      "step 1830, test loss 90.8766\n",
      "step 1860, test loss 104.622\n",
      "step 1890, test loss 114.667\n",
      "step 1920, test loss 114.257\n",
      "step 1950, test loss 105.174\n",
      "step 1980, test loss 82.4972\n",
      "step 2010, test loss 75.2543\n",
      "step 2040, test loss 90.8002\n",
      "step 2070, test loss 94.4492\n",
      "step 2100, test loss 129.543\n",
      "step 2130, test loss 69.5175\n",
      "step 2160, test loss 88.7893\n",
      "step 2190, test loss 111.02\n",
      "step 2220, test loss 92.9853\n",
      "step 2250, test loss 113.485\n",
      "step 2280, test loss 82.4515\n",
      "step 2310, test loss 92.042\n",
      "step 2340, test loss 84.9253\n",
      "step 2370, test loss 90.0729\n",
      "step 2400, test loss 96.0839\n",
      "step 2430, test loss 61.6332\n",
      "step 2460, test loss 82.0112\n",
      "step 2490, test loss 113.817\n",
      "step 2520, test loss 82.6119\n",
      "step 2550, test loss 104.3\n",
      "step 2580, test loss 88.4731\n",
      "step 2610, test loss 79.0084\n",
      "step 2640, test loss 94.4744\n",
      "step 2670, test loss 104.544\n",
      "step 2700, test loss 90.621\n",
      "step 2730, test loss 83.0548\n",
      "step 2760, test loss 97.4589\n",
      "step 2790, test loss 77.2217\n",
      "step 2820, test loss 107.244\n",
      "step 2850, test loss 74.7696\n",
      "step 2880, test loss 151.005\n",
      "step 2910, test loss 51.7819\n",
      "step 2940, test loss 116.55\n",
      "step 2970, test loss 97.6235\n",
      "step 3000, test loss 122.816\n",
      "step 3030, test loss 105.099\n",
      "step 3060, test loss 103.631\n",
      "step 3090, test loss 118.565\n",
      "step 3120, test loss 85.8971\n",
      "step 3150, test loss 144.356\n",
      "step 3180, test loss 136.181\n",
      "step 3210, test loss 90.9624\n",
      "step 3240, test loss 112.742\n",
      "step 3270, test loss 76.97\n",
      "step 3300, test loss 65.5764\n",
      "step 3330, test loss 110.292\n",
      "step 3360, test loss 79.3762\n",
      "step 3390, test loss 110.006\n",
      "step 3420, test loss 101.434\n",
      "step 3450, test loss 85.999\n",
      "step 3480, test loss 112.492\n",
      "step 3510, test loss 78.7377\n",
      "step 3540, test loss 78.7233\n",
      "step 3570, test loss 82.9203\n",
      "step 3600, test loss 92.9487\n",
      "step 3630, test loss 76.0544\n",
      "step 3660, test loss 56.3834\n",
      "step 3690, test loss 95.4654\n",
      "step 3720, test loss 62.7576\n",
      "step 3750, test loss 126.818\n",
      "step 3780, test loss 61.0703\n",
      "step 3810, test loss 63.3255\n",
      "step 3840, test loss 106.498\n",
      "step 3870, test loss 80.0668\n",
      "step 3900, test loss 105.051\n",
      "step 3930, test loss 96.4102\n",
      "step 3960, test loss 81.0734\n",
      "step 3990, test loss 67.8788\n",
      "step 4020, test loss 74.441\n",
      "step 4050, test loss 68.993\n",
      "step 4080, test loss 99.3138\n",
      "step 4110, test loss 98.4087\n",
      "step 4140, test loss 76.5889\n",
      "step 4170, test loss 60.3622\n",
      "step 4200, test loss 67.9156\n",
      "step 4230, test loss 95.451\n",
      "step 4260, test loss 77.4324\n",
      "step 4290, test loss 89.6005\n",
      "step 4320, test loss 103.618\n",
      "step 4350, test loss 47.0243\n",
      "step 4380, test loss 63.1509\n",
      "step 4410, test loss 94.4079\n",
      "step 4440, test loss 72.05\n",
      "step 4470, test loss 126.016\n",
      "step 4500, test loss 77.7123\n",
      "step 4530, test loss 111.143\n",
      "step 4560, test loss 91.3767\n",
      "step 4590, test loss 95.7367\n",
      "step 4620, test loss 99.096\n",
      "step 4650, test loss 138.441\n",
      "step 4680, test loss 76.0714\n",
      "step 4710, test loss 128.673\n",
      "step 4740, test loss 82.8446\n",
      "step 4770, test loss 112.064\n",
      "step 4800, test loss 69.5055\n",
      "step 4830, test loss 90.0648\n",
      "step 4860, test loss 73.4727\n",
      "step 4890, test loss 83.4215\n",
      "step 4920, test loss 110.834\n",
      "step 4950, test loss 122.99\n",
      "step 4980, test loss 98.4076\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.squared_difference(y_,y_conv), name='loss')\n",
    "train_step = tf.train.AdamOptimizer(5e-5).minimize(loss)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "size = 30\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(5000):\n",
    "        batch = random_batch(train_coordinate,train_target,size)\n",
    "        test_batch = random_batch(test_coordinate,test_target,50)\n",
    "        if i % 30 == 0:\n",
    "            #train_accuracy = accuracy.eval(feed_dict={\n",
    "                  #x: np.float32(coordinate), y_: np.float32(target), keep_prob: 1.0})\n",
    "            print('step %d, test loss %g' % (i, loss.eval(feed_dict={\n",
    "                  x: test_batch[0], y_: test_batch[1], keep_prob: 1.0})))\n",
    "        if i % 500 == 0:    \n",
    "            saver.save(sess, './my-model6')\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def test_model(test_num):\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "    save_model_path = './my-model6'\n",
    "    #test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "    compare_batch = random_batch(test_coordinate,test_target,test_num)\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "    \n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x_:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y_:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob0:0')\n",
    "        loaded_loss = loaded_graph.get_tensor_by_name('loss:0')\n",
    "        loaded_yconv = loaded_graph.get_tensor_by_name('y_conv:0')\n",
    "\n",
    "        predict_y = loaded_yconv.eval(feed_dict={loaded_x: test_coordinate[:test_num],\n",
    "                                       loaded_y: test_target[:test_num], loaded_keep_prob: 1.0})\n",
    "        real_y = loaded_y.eval(feed_dict={loaded_x: test_coordinate[:test_num],\n",
    "                                       loaded_y: test_target[:test_num], loaded_keep_prob: 1.0})       \n",
    "        #print(tf.nn.top_k(conseq,10,sorted=False))\n",
    "    return predict_y,real_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my-model6\n",
      "INFO:tensorflow:Restoring parameters from ./my-model6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   7.2552886 ,   24.47680092],\n",
       "       [   8.01174831,    4.78395987],\n",
       "       [   8.68395519,   13.30039978],\n",
       "       [  11.80395508,    4.08218002],\n",
       "       [  11.80395889,    6.9609499 ],\n",
       "       [  12.31445503,   19.05990028],\n",
       "       [  12.95008087,    1.75127006],\n",
       "       [  16.00240135,    6.27271986],\n",
       "       [  17.70624733,   18.69039917],\n",
       "       [  18.49664688,   22.35589981],\n",
       "       [  18.62885284,   19.15099907],\n",
       "       [  18.88774872,   11.15680027],\n",
       "       [  18.88774872,   19.91360092],\n",
       "       [  18.88774872,   25.65990067],\n",
       "       [  19.17640305,   20.08370018],\n",
       "       [  19.80217934,   26.16379929],\n",
       "       [  20.56017494,   21.37619972],\n",
       "       [  21.44882202,   27.58270073],\n",
       "       [  22.16014671,   16.85519981],\n",
       "       [  22.59461212,   17.3512001 ],\n",
       "       [  22.83474159,   29.77980042],\n",
       "       [  23.45298386,   18.48920059],\n",
       "       [  24.14907646,   22.85250092],\n",
       "       [  24.38992691,   24.41469955],\n",
       "       [  25.28885269,   18.93919945],\n",
       "       [  25.96772957,   23.61190033],\n",
       "       [  26.27028465,   48.00569916],\n",
       "       [  26.52621651,   38.56200027],\n",
       "       [  27.73370743,   31.52770042],\n",
       "       [  29.20386124,   30.11739922],\n",
       "       [  29.65462685,   26.81469917],\n",
       "       [  30.44922066,   22.0678997 ],\n",
       "       [  31.04592133,   24.36249924],\n",
       "       [  31.11973763,   22.31240082],\n",
       "       [  31.2431469 ,   34.39450073],\n",
       "       [  32.27429199,   35.78110123],\n",
       "       [  32.87120819,   38.06729889],\n",
       "       [  33.06595612,   48.55250168],\n",
       "       [  33.13736343,   22.12220001],\n",
       "       [  34.10177612,   35.90969849],\n",
       "       [  34.22652817,   37.55569839],\n",
       "       [  36.0915184 ,   54.17259979],\n",
       "       [  36.15276337,   44.72589874],\n",
       "       [  37.52355194,   46.42259979],\n",
       "       [  38.32759094,   43.28770065],\n",
       "       [  39.45663834,   18.03170013],\n",
       "       [  40.95653534,   36.11009979],\n",
       "       [  41.40594482,   46.34889984],\n",
       "       [  41.7857666 ,   56.66650009],\n",
       "       [  41.967556  ,   44.43209839],\n",
       "       [  42.9412117 ,   41.11470032],\n",
       "       [  43.80664062,   50.5141983 ],\n",
       "       [  44.42777252,   27.95809937],\n",
       "       [  44.56301117,   48.50920105],\n",
       "       [  45.65007782,   46.87599945],\n",
       "       [  45.65724945,   27.27370071],\n",
       "       [  45.82610321,   44.99599838],\n",
       "       [  46.20574951,   48.59090042],\n",
       "       [  47.4953537 ,   47.30590057],\n",
       "       [  47.77080154,   41.70640182],\n",
       "       [  47.95613861,   43.3205986 ],\n",
       "       [  48.38481903,   42.76580048],\n",
       "       [  48.39796829,   38.0489006 ],\n",
       "       [  48.59838104,   48.97119904],\n",
       "       [  49.15514374,   33.52460098],\n",
       "       [  49.23094177,   45.3091011 ],\n",
       "       [  49.78686142,   62.6568985 ],\n",
       "       [  49.86798477,   43.97050095],\n",
       "       [  50.99419022,   58.49459839],\n",
       "       [  51.29818726,   63.55160141],\n",
       "       [  51.78820801,   37.02600098],\n",
       "       [  51.92867661,   45.96170044],\n",
       "       [  52.08377838,   45.71670151],\n",
       "       [  52.33652496,   57.11920166],\n",
       "       [  54.38951874,   46.05899811],\n",
       "       [  55.15221405,   56.62200165],\n",
       "       [  56.84348679,   73.45120239],\n",
       "       [  57.65175629,   49.66770172],\n",
       "       [  57.78878403,   66.0632019 ],\n",
       "       [  58.60549927,   32.72829819],\n",
       "       [  58.76013184,   68.89510345],\n",
       "       [  58.92553329,   55.14139938],\n",
       "       [  59.77635193,   54.61429977],\n",
       "       [  59.83913803,   55.76610184],\n",
       "       [  59.92656326,   34.14479828],\n",
       "       [  60.25452423,   54.68000031],\n",
       "       [  61.2650032 ,   53.1719017 ],\n",
       "       [  61.45172119,   75.59629822],\n",
       "       [  62.66134262,   67.41799927],\n",
       "       [  62.68146515,   68.51799774],\n",
       "       [  63.94708252,   56.99620056],\n",
       "       [  64.00715637,   69.99500275],\n",
       "       [  65.88373566,   70.22920227],\n",
       "       [  67.87699127,   64.81620026],\n",
       "       [  68.02326965,   65.95829773],\n",
       "       [  70.16262817,   86.11940002],\n",
       "       [  74.73251343,   78.25900269],\n",
       "       [  81.19078827,   94.79859924],\n",
       "       [ 100.5163269 ,   97.76509857],\n",
       "       [ 101.87471771,  102.53600311]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num = 100\n",
    "a = test_model(test_num)[0]\n",
    "b = test_model(test_num)[1]\n",
    "c = np.zeros([test_num,2])\n",
    "c[:,0]=np.reshape(a,[test_num])\n",
    "c[:,1]=np.reshape(b,[test_num])\n",
    "c[np.argsort(c[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
