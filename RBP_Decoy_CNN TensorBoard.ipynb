{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBP='1A34 1AQ3 1BMV 1F7V 1H4Q 1JBT 1L9A 1MZP 1WMQ 1YYK 1ZL3 2ANN 2ATW 2AZ2 2BX2 2DR2 2DU4 2G4B 2GXB 3AMT'\n",
    "#the rbp we gonna analyze\n",
    "rbp=RBP.split()\n",
    "len(rbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "for i in range(20):\n",
    "    f = open(rbp[i]+'/complex1.pdb')\n",
    "    for x in f.readlines():\n",
    "        if x.split()[3] not in name:\n",
    "            name.append(x.split()[3])\n",
    "    f.close()\n",
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "protein = ['THR',\n",
    " 'GLY',\n",
    " 'ASP',\n",
    " 'ASN',\n",
    " 'SER',\n",
    " 'VAL',\n",
    " 'MET',\n",
    " 'ILE',\n",
    " 'ARG',\n",
    " 'ALA',\n",
    " 'TYR',\n",
    " 'PRO',\n",
    " 'LYS',\n",
    " 'TRP',\n",
    " 'PHE',\n",
    " 'GLU',\n",
    " 'GLN',\n",
    " 'LEU',\n",
    " 'HIS',\n",
    " 'CYS',\n",
    " 'A',\n",
    " 'G',\n",
    " 'C',\n",
    " 'U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num = 24\n",
    "comp_num = 1000\n",
    "total = 20*comp_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f12b28ec9564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtmp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtmp_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mtmp_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtmp_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shawn/ENTER/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#measure the size of the RBP\n",
    "\n",
    "size=np.zeros([20,comp_num,6])\n",
    "for i in tqdm(range(20)):#for every rbp\n",
    "    for j in range(comp_num):\n",
    "        r=rbp[i]\n",
    "        f = open(r+'/complex%d.pdb'%(j+1))\n",
    "        tmp_x = []\n",
    "        tmp_y = []\n",
    "        tmp_z = []\n",
    "        for x in f.readlines():\n",
    "            tmp_z.append(np.float32(x[-9:-1]))\n",
    "            tmp_y.append(np.float32(x[-17:-9]))\n",
    "            tmp_x.append(np.float32(x[-25:-17]))\n",
    "        size[i,j,0]=max(tmp_x)\n",
    "        size[i,j,3]=min(tmp_x)\n",
    "        size[i,j,1]=max(tmp_y)\n",
    "        size[i,j,4]=min(tmp_y)\n",
    "        size[i,j,2]=max(tmp_z)\n",
    "        size[i,j,5]=min(tmp_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [57:06<00:00, 168.85s/it]\n"
     ]
    }
   ],
   "source": [
    "length=np.zeros([20,comp_num,3])\n",
    "length[:,:,0]=(size[:,:,0]-size[:,:,3])/num\n",
    "length[:,:,1]=(size[:,:,1]-size[:,:,4])/num\n",
    "length[:,:,2]=(size[:,:,2]-size[:,:,5])/num\n",
    "for k in tqdm(range(20)):#for every rbp\n",
    "    coordinate=np.zeros((comp_num,num,num,num,24),dtype = int)\n",
    "    for j in range(comp_num):\n",
    "        r=rbp[k]\n",
    "        f = open(r+'/complex%d.pdb'%(j+1))\n",
    "        t=f.readlines()[0].split()[-4]\n",
    "        cotmp=np.zeros(4)\n",
    "        f = open(r+'/complex%d.pdb'%(j+1))\n",
    "        for x in f.readlines():\n",
    "            #print(x)\n",
    "            if x[22:26]!=t and cotmp[3]!=0:\n",
    "                #print(cotmp,t,tmp)\n",
    "                position = cotmp[0:3]/cotmp[3]-size[k,j,3:]\n",
    "                #print(cotmp[0:3]/cotmp[3])\n",
    "                ix=position[0]//length[k,j,0]\n",
    "                iy=position[1]//length[k,j,1]\n",
    "                iz=position[2]//length[k,j,2]\n",
    "                #if ix > 10:\n",
    "                    #print(k,j,position)\n",
    "                if i < 24:\n",
    "                    coordinate[j,int(ix),int(iy),int(iz),i]+=1\n",
    "                cotmp=np.zeros(4)\n",
    "            #save center of the acid or RNA in coord\n",
    "\n",
    "            tmp=np.zeros(4)\n",
    "            tmp[2]+=np.float32(x[-9:-1])\n",
    "            tmp[1]+=np.float32(x[-17:-9])\n",
    "            tmp[0]+=np.float32(x[-25:-17])\n",
    "            tmp[3]+=1\n",
    "            #print(tmp)\n",
    "            cotmp+=tmp\n",
    "\n",
    "            #count every atom in each acid or RNA\n",
    "\n",
    "            n =x.split()[3]\n",
    "            i = name.index(n)     \n",
    "            t =x[22:26]\n",
    "            #update the tmp index \n",
    "    coordi = coordinate.reshape([comp_num,num*num*num*24])\n",
    "    np.savetxt(protein[k]+'24',coordi,fmt = '%.0e')\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = list(range(total))\n",
    "rd.shuffle(index)\n",
    "train_index = index[:-300]\n",
    "test_index = index[-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_coordinate = coordinate.reshape(20*comp_num,num,num,num,24)[train_index]\n",
    "test_coordinate = coordinate.reshape(20*comp_num,num,num,num,24)[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = np.zeros((20,comp_num))\n",
    "\n",
    "for k in range(20):\n",
    "    tmp=[]\n",
    "    f=open(rbp[k]+'/'+rbp[k]+'.rmsd.out.tensorflow')\n",
    "    for x in f.readlines()[1:]:\n",
    "        tmp.append(np.float32(x[23:32]))\n",
    "    target[k]=np.float32(tmp[0:comp_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_target = target.reshape(20*comp_num,1)[train_index]\n",
    "test_target = target.reshape(20*comp_num,1)[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,  num, num, num, 24], name='x_')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2x2(x,layer_name):\n",
    "    with tf.name_scope(layer_name):\n",
    "        pool = tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 2, 1], padding='SAME',name='pool')\n",
    "        tf.summary.histogram('pool', pool)\n",
    "        return pool\n",
    "    \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def random_batch(data,label,size):\n",
    "    index =  np.random.choice(len(label), size, replace=False)\n",
    "    batch_data = data[index]\n",
    "    batch_label = label[index]\n",
    "    return batch_data,batch_label\n",
    "\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "        \n",
    "def conv_layer(input_tensor,weight_dim, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    \"\"\"Reusable code for making a simple neural net layer.\n",
    "\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "    \"\"\"\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([weight_dim[0],weight_dim[1],weight_dim[2], input_dim,output_dim])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = conv3d(input_tensor, weights) + biases\n",
    "            tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activation')\n",
    "        tf.summary.histogram('activations', activations)\n",
    "        return activations\n",
    "    \n",
    "def dropout_layer(x,layer_name,keep_prob=0.5):\n",
    "    with tf.name_scope(layer_name):\n",
    "        drop = tf.nn.dropout(x, keep_prob)\n",
    "        tf.summary.histogram('dropped', drop)\n",
    "        return drop\n",
    "    \n",
    "\n",
    "def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "    # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([input_dim, output_dim])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "            tf.summary.histogram('pre_activations', preactivate)\n",
    "    activations = act(preactivate, name='activation')\n",
    "    tf.summary.histogram('activations', activations)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_image = tf.cast(tf.reshape(x, [-1, num, num, num, 24]),tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_conv1 = conv_layer(x_image,[3,3,3],24,32,'conv1')\n",
    "h_conv2 = conv_layer(h_conv1,[6,6,6],32,32,'conv2')\n",
    "h_pool1 = max_pool_2x2x2(h_conv2,'pool1')\n",
    "\n",
    "h_conv3 = conv_layer(h_pool1,[4,4,4],32,32,'conv3')\n",
    "h_conv4 = conv_layer(h_conv3,[5,5,5],32,32,'conv4')\n",
    "h_pool2 = max_pool_2x2x2(h_conv4,'pool2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_flat1 = tf.reshape(h_pool2, [-1, int(num * num* num /2)])\n",
    "h_fc1 = nn_layer(h_flat1,int(num * num* num /2),256,'fc1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob0')\n",
    "h_drop = dropout_layer(h_fc1,'dropout', keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_conv = nn_layer(h_drop,256,1,'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "W_conv1 = weight_variable([3, 3, 3, 24, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv3d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 5, 32, 32])\n",
    "b_conv2 = bias_variable([32])\n",
    "h_conv2 = tf.nn.relu(conv3d(h_conv1, W_conv2) + b_conv2)\n",
    "\n",
    "h_pool1 = max_pool_2x2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "W_conv3 = weight_variable([4, 4, 4, 32, 32])\n",
    "b_conv3 = bias_variable([32])\n",
    "h_conv3 = tf.nn.relu(conv3d(h_pool1, W_conv3) + b_conv3)\n",
    "\n",
    "W_conv4 = weight_variable([5, 5, 5, 32, 32])\n",
    "b_conv4 = bias_variable([32])\n",
    "h_conv4 = tf.nn.relu(conv3d(h_conv3, W_conv4) + b_conv4)\n",
    "\n",
    "h_pool2 = max_pool_2x2x2(h_conv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "W_fc1 = weight_variable([int(num* num *num/2), 128])\n",
    "b_fc1 = bias_variable([128])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, int(num * num* num /2)])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob0')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "W_fc2 = weight_variable([128, 128])\n",
    "b_fc2 = bias_variable([128])\n",
    "\n",
    "y_conv = tf.abs(tf.add(tf.matmul(h_fc1_drop, W_fc2) , b_fc2),name='y_conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.squared_difference(y_,y_conv), name='loss')\n",
    "    tf.summary.scalar('loss',loss)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(5e-5).minimize(loss)\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter( './my-model9/train',\n",
    "                                      sess.graph)\n",
    "test_writer = tf.summary.FileWriter('./my-model9/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, test loss 2539.63\n",
      "step 50, test loss 609.166\n",
      "step 100, test loss 365.378\n",
      "step 150, test loss 387.944\n",
      "step 200, test loss 336.31\n",
      "step 250, test loss 219.58\n",
      "step 300, test loss 314.083\n",
      "step 350, test loss 156.367\n",
      "step 400, test loss 252.825\n",
      "step 450, test loss 172.949\n",
      "step 500, test loss 235.103\n",
      "step 550, test loss 199.1\n",
      "step 600, test loss 272.376\n",
      "step 650, test loss 155.669\n",
      "step 700, test loss 289.078\n",
      "step 750, test loss 179.893\n",
      "step 800, test loss 155.38\n",
      "step 850, test loss 231.538\n",
      "step 900, test loss 92.6684\n",
      "step 950, test loss 128.428\n",
      "step 1000, test loss 124.673\n",
      "step 1050, test loss 153.558\n",
      "step 1100, test loss 165.869\n",
      "step 1150, test loss 110.932\n",
      "step 1200, test loss 101.958\n",
      "step 1250, test loss 215.509\n",
      "step 1300, test loss 159.026\n",
      "step 1350, test loss 141.747\n",
      "step 1400, test loss 137.719\n",
      "step 1450, test loss 85.4829\n",
      "step 1500, test loss 98.5884\n",
      "step 1550, test loss 159.801\n",
      "step 1600, test loss 132.105\n",
      "step 1650, test loss 131.271\n",
      "step 1700, test loss 161.782\n",
      "step 1750, test loss 156.201\n",
      "step 1800, test loss 136.758\n",
      "step 1850, test loss 172.593\n",
      "step 1900, test loss 122.499\n",
      "step 1950, test loss 194.094\n",
      "step 2000, test loss 87.1161\n",
      "step 2050, test loss 140.722\n",
      "step 2100, test loss 194.979\n",
      "step 2150, test loss 156.658\n",
      "step 2200, test loss 129.731\n",
      "step 2250, test loss 143.076\n",
      "step 2300, test loss 137.711\n",
      "step 2350, test loss 158.298\n",
      "step 2400, test loss 180.194\n",
      "step 2450, test loss 121.577\n",
      "step 2500, test loss 103.879\n",
      "step 2550, test loss 165.208\n",
      "step 2600, test loss 134.571\n",
      "step 2650, test loss 153.11\n",
      "step 2700, test loss 158.031\n",
      "step 2750, test loss 144.321\n",
      "step 2800, test loss 80.7581\n",
      "step 2850, test loss 145.138\n",
      "step 2900, test loss 179.244\n",
      "step 2950, test loss 215.155\n",
      "step 3000, test loss 137.255\n"
     ]
    }
   ],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "\n",
    "size = 30\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(3001):\n",
    "        batch = random_batch(train_coordinate,train_target,size)\n",
    "        summary, _ = sess.run([merged, train_step],feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})  \n",
    "        train_writer.add_summary(summary, i)\n",
    "        if i % 50 == 0:\n",
    "            #train_accuracy = accuracy.eval(feed_dict={\n",
    "                  #x: np.float32(coordinate), y_: np.float32(target), keep_prob: 1.0})\n",
    "            test_batch = random_batch(test_coordinate,test_target,50)\n",
    "            summary, los = sess.run([merged, loss], feed_dict={\n",
    "                  x: test_batch[0], y_: test_batch[1], keep_prob: 1.0})\n",
    "            test_writer.add_summary(summary, i)\n",
    "            print('step %d, test loss %g' % (i, los))\n",
    "            #print('step %d, min pred %g' % (i, min(y_conv.eval(feed_dict={\n",
    "            #      x: test_batch[0], y_: test_batch[1], keep_prob: 1.0}))))\n",
    "        if i % 500 == 0:    \n",
    "            saver.save(sess, './my-model9/iter %d'%i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def test_model(test_coordinate,test_target):\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "    save_model_path = './my-model6'\n",
    "    #test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "    \n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x_:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y_:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob0:0')\n",
    "        loaded_loss = loaded_graph.get_tensor_by_name('loss:0')\n",
    "        loaded_yconv = loaded_graph.get_tensor_by_name('y_conv:0')\n",
    "\n",
    "        predict_y = loaded_yconv.eval(feed_dict={loaded_x: test_coordinate,\n",
    "                                       loaded_y: test_target, loaded_keep_prob: 1.0})\n",
    "        real_y = loaded_y.eval(feed_dict={loaded_x: test_coordinate,\n",
    "                                       loaded_y: test_target, loaded_keep_prob: 1.0})       \n",
    "        #print(tf.nn.top_k(conseq,10,sorted=False))\n",
    "    return predict_y,real_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 20/20 [1:49:49<00:00, 326.82s/it]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros([20,1000,2])\n",
    "for i in tqdm(range(20)):\n",
    "    test_data = np.loadtxt(protein[i]+'24')\n",
    "    for j in range(20):\n",
    "        l = int(comp_num/20)\n",
    "        test_coordinate = test_data[j*l:j*l+l].reshape([l,num,num,num,24])\n",
    "        test_target = target[i,j*l:j*l+l].reshape([l,1])\n",
    "        a[i,j*l:j*l+l,0]=test_model(test_coordinate,test_target)[0].reshape([l])\n",
    "        a[i,j*l:j*l+l,1]=test_target.reshape([l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9MYY0+Es0BtjTIf7/2BcYBoq9jibAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa72eac50f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = a.reshape([20000,2])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(b[:,0],b[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def linefit(x , y):\n",
    "    N = float(len(x))\n",
    "    sx,sy,sxx,syy,sxy=0,0,0,0,0\n",
    "    for i in range(0,int(N)):\n",
    "        sx  += x[i]\n",
    "        sy  += y[i]\n",
    "        sxx += x[i]*x[i]\n",
    "        syy += y[i]*y[i]\n",
    "        sxy += x[i]*y[i]\n",
    "    a = (sy*sx/N -sxy)/( sx*sx/N -sxx)\n",
    "    b = (sy - a*sx)/N\n",
    "    r = abs(sy*sx/N-sxy)/math.sqrt((sxx-sx*sx/N)*(syy-sy*sy/N))\n",
    "    return a,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0311880791554344, 0.17736816883313586, 0.90151415178234207)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linefit(b[:,0],b[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
